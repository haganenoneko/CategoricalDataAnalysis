{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Analyzing Contingency Tables\n",
    "Data is in a table with rows and columns. \n",
    "- can use binomial for a single row or single column\n",
    "- multinomial to consider multiple cells at once \n",
    "\n",
    "## Relative risk and odds ratio\n",
    "- Relative risk = $\\pi_i/\\pi_j$ \n",
    "\t- sampling distribution is highly skewed unless sample sizes are large \n",
    "- odds = $\\pi_i / (1-\\pi_i)$ \n",
    "\t- odds of success, e.g. if odds = 3, then we expect 3 successes for each failure \n",
    "\t- $\\pi =$ odds/(1 + odds) \n",
    "- odds ratio = $\\theta = \\Large \\frac{\\text{odds}_1}{\\text{odds}_2} = \\frac{\\pi_1 / (1-\\pi_1)}{\\pi_2 / (1 - \\pi_2) }  = \\frac{n_{11}n_{22}}{n_{21}n_{12}}$  \n",
    "\t- like RR, sampling distribution also highly skewed unless ample size is large \n",
    "\t- invariant under transposing rows/columns\n",
    "\t- $\\theta = RR \\times \\large \\frac{1 - \\pi_2}{1 - \\pi_1} \\implies$ if $\\pi_1, \\pi_2 \\approx 0$, then $\\theta \\approx RR$ \n",
    "-  in some cases/designs, only one of RR or OR can be estimated\n",
    "\t- eg Table 2.3, where study was designed so that equal numbers of pts with and w/o lung cancer are recruited, and then count number of smokers within each group. \n",
    "\t\t- Due to this design, $P(\\text{disease}) = P(\\text{no disease}) = 0.5$, which is unrealistic. \n",
    "\t\t- Thus, cannot estimate $P(\\text{smoking} \\mid \\text{disease}) = P(\\text{smoking} \\cap \\text{disease}) / P(\\text{disease})$ \n",
    "\t\t- However, we have $P(\\text{disease} \\mid \\text{smoking})$, and since $OR$ is symmetric, we can use $P(X \\mid Y)$ or $P(Y \\mid X)$ and get the same result. \n",
    "\t\t- From above, if we expect $P(\\text{disease} \\mid \\text{smoking})$ and $P(\\text{disease} \\mid \\text{no smoking})$ to both be small, then $OR \\approx RR$ \n",
    "- inference for $\\theta$ and $\\log \\theta$\n",
    "\t- since the distribution fo $\\theta$ is highly skewed, mostly use $\\log \\theta$\n",
    "\t- thus, use CLT to find Wald CIs for $\\log \\theta$, then exponentiate these to get values in untransformed space\n",
    "\n",
    "$$\n",
    "\\begin{align} \n",
    "var(\\log \\hat{\\theta}) &= \\sum_{i,j} \\frac{1}{n_{ij}}  \\\\\n",
    "E[\\log \\hat{\\theta}] &= \\log \\theta \\\\\n",
    "\\mathcal{I} &= \\left[ \\log \\hat{\\theta} \\pm \n",
    "\\frac{q_{\\alpha/2}}{\\sqrt{\\sum_{i,j} \\frac{1}{n_{ij}}}}  \\right] \n",
    "\\end{align} \n",
    "$$\n",
    "\n",
    "- standardized residual \n",
    "\t- $p_{ij}$ = observed fraction in the $(i,j)$-th cell\n",
    "\t- $\\pi_i$ and $\\pi_j$ are expected row and column frequencies, e.g. $\\pi_i =$ (sum of row i)/$n$ \n",
    "\t- used when raw difference is insufficient, eg since larger frequencies lead to larger differences\n",
    "$$\n",
    "r = \\frac{n(p_{ij} - \\pi_i \\pi_j)}{\\sqrt{n\\pi_i\\pi_j(1-\\pi_i)(1-\\pi_j)}} \\sim N(0,1)\n",
    "$$\n",
    "\n",
    "### Tests of independence\n",
    "$$\n",
    "\\begin{align} \n",
    "\\text{Chi-squared} \\quad \n",
    "X^2 &= \\sum_{i,j} \\frac{(n_{ij} - \\mu_{ij})^2}{\\mu_{ij}} \n",
    "\\rightarrow \\chi^2 \\\\\n",
    "\\text{Likelihood ratio} \\quad \n",
    "G^2 &= 2 \\sum_{ij} n_{ij} \\log \\frac{n_{ij}}{\\mu_{ij}} \n",
    "\\rightarrow \\chi^2 \\\\\n",
    "\\mu_{ij} &= n \\hat{\\pi}_{i,:} \\hat{\\pi}_{:,j} = \n",
    "n \\cdot \\frac{n_{i,:}}{n} \\cdot \\frac{n_{:,j}}{n} \\\\\n",
    "\t&= \\frac{n_{i,:} \\ n_{:,j}}{n} \n",
    "\\end{align} \n",
    "$$\n",
    "Where\n",
    "- $n_{ij}$ are counts in the (i,j)-th cell\n",
    "- $\\mu_{ij}$ is the expected frequency of $n_{ij}$, assuming independence\n",
    "- $n_{i,:}$ and $n_{:,j}$ are marginal totals of the i-th row and j-th column, resp. \n",
    "- for a $(r \\times c)$ contingency table, the limiting $\\chi^2$ distributions of $X^2$ and $G^2$ have $(r-1)(c-1)$ degrees of freedom (dofs)\n",
    "\t- since each row/column contains probabilities that sum to 1, one cell in each row/column can be solved knowing the rest \n",
    "\t- under the null hypothesis, every cell in each row/column has the same probability\n",
    "\t\t- every cell in the k-th row will have the same probability as the marginal row probability of the k-th row, ie $\\pi_{k,:} = \\pi_{k,1} = \\pi_{k,2} = \\cdots$ \n",
    "\t\t- since the marginal row probabilities sum to 1, there are $r-1$ non-redundant row probabilities\n",
    "\t\t- the same logic above applies to the columns as well, so there are $(r-1) + (c-1)$ total parameters when we assume independence, ie under $H_0$ \n",
    "\t- under the alternative hypothesis, we only constrain the total sum to 1, so there are $rc-1$ non redundant parameters \n",
    "\t- dofs = no. parameters under $H_1$ - no. parameters under $H_0$ = $rc - 1 - (r-1) - (c-1) = (r-1)(c-1)$ \n",
    "\n",
    "- chi-squared test of independence\n",
    "\t- Pearson $X^2$, see [[L15 Goodness of Fit Test for Discrete Distributions#Squared difference goes to Chi-squared with d-1 dofs|L15 Goodness of Fit Test]]\n",
    "\t- so-called $G^2$, ie likelihood ratio test \n",
    "- $X^2$ vs $G^2$\n",
    "\t- for $G^2$, contingency tables can be decomposed such that the $G^2$ for individual subtables will sum to the $G^2$ for the full table \n",
    "\t\t- however, this is not the case for $X^2$\n",
    "\t- $G^2$ converges more slowly to $\\chi^2$ distribution, so needs larger sample size\n",
    "\n",
    "## Ordinal data\n",
    "- test statistic $M^2 = (n-1)R^2$ , where $R^2$ is the correlation coefficient\n",
    "\t- $M^2 \\sim \\chi^2_1$ for large n \n",
    "- like $X^2$ and $G^2$, $M^2$ does not differentiate between response and explanatory, e.g. we can use whichever and get the same value for $M^2$ \n",
    "\t- $u_i$ are row scores, $v_j$ are column scores\n",
    "$$R^2 = \\frac{cov(u, v)}{\\sigma_u \\sigma_v}\n",
    "= \\frac{\\sum_{i,j} (u_i - E[u])(v_j - E[v]) \\cdot \\hat{\\pi}_{ij}}\n",
    "{\\sqrt{\n",
    "\t\\left( \\sum_{i} (u_i - E[u])^2 \\cdot \\hat{\\pi}_{i,:} \\right)\n",
    "\t\\left( \\sum_{j} (v_j - E[v])^2 \\cdot \\hat{\\pi}_{:,j} \\right)\n",
    "}} \n",
    "$$\n",
    "- assigning scores, eg midpoints of numerical categories \n",
    "- for very ==unbalanced== (ie one category has very few samples, another has many samples) data, $R$ cannot be large \n",
    "- ==ordinal tests often have greater power== bc $M^2$ follows $\\chi^2_1$ whereas $X^2, G^2 \\sim \\chi^2_{(r-1)(c-1)}$\n",
    "\t- $\\chi^2$ right shifts and broadens for larger dofs => distribution of $M^2$ falls off more sharply than equal values of $X^2, G^2$, \n",
    "\t- ie p-values for $M^2$ are smaller than equivalent values of $X^2, G^2$ \n",
    "\n",
    "## Fisher's exact test\n",
    "- an exact frequentist method for fixed row and column marginals \n",
    "- probabilities of cell counts given by hypergeometric distribution  \n",
    "\t- discrete, so use mid-P value (use half of the observed result + probability of more extreme results)\n",
    "$$\n",
    "P(n_{11}) = \n",
    "\\frac{\\begin{pmatrix} n_{1,:} \\\\ n_{11} \\end{pmatrix} \n",
    "\\begin{pmatrix} n_{2,:} \\\\ n_{:,1} - n_{11} \\end{pmatrix} }\n",
    "{\\begin{pmatrix} n \\\\ n_{:,1} \\end{pmatrix} } \n",
    "$$\n",
    "\n",
    "### Association in 3-way tables\n",
    "| Victim | Defendant | Death Penalty | No Death Penalty |\n",
    "| ------ | --------- | ------------- | ---------------- |\n",
    "| White  | White     | 53            | 414              |\n",
    "|        | Black     | 11            | 37               |\n",
    "| Black  | White     | 0             | 16               |\n",
    "|        | Black     | 4             | 139              |\n",
    "| Total  | White     | 53            | 430              |\n",
    "|        | Black     | 15            | 176                 |\n",
    "\n",
    "Marginal odds ratios\n",
    "- victim x defendant = $\\frac{(53+414)(4+139)}{(11+37)(0+16)} = 87$ , ie sum over death penalty yes/no\n",
    "\t- \"odds that a white defendant had white victims is ==87x== the odds that a black defendant had white victims\", ie $n_{11} / n_{21}$ \n",
    "-  defendant x death penalty = $\\frac{53 \\cdot 176}{15 \\cdot 430} = 1.45$\n",
    "\t- \"odds that a white defendant receives the death penalty is ==45%==  higher than the odds of a black defendant receiving the death penalty\"\n",
    "Conditional odds ratios\n",
    "- (defendant x death penalty | victim = white) = $\\frac{53 \\cdot 37}{11 \\cdot 414}=0.43$\n",
    "\t- \"given white victim, odds that a white defendant receives the death penalty is 43% that of a black defendant\"\n",
    "- (victim x defendant | death penalty = no) = $\\frac{414\\cdot 139}{37 \\cdot 16} = 97$ \n",
    "\t-   \"given no death penalty, odds that a white defendant had white victim is 97x that of a black defendant\"\n",
    "\n",
    "Conditional independence vs marginal independence\n",
    "- associations can change when we marginalize/condition on different variables\n",
    "- ==homogeneous association== => all conditional odds are equal $\\theta_1 = \\theta_2 = \\cdots$\n",
    "\t- a special case is ==conditional independence== => conditional odds = 1 \n",
    "- conditional independence does not imply marginal independence\n",
    "\n",
    "## Exercises\n",
    "2.11 Find a 95% confidence interval for the population odds ratio.\n",
    "| Vote in 2008 | Obama | Romney |\n",
    "| ------------ | ----- | ------ |\n",
    "| Obama        | 802   | 53     |\n",
    "| McCain       | 34    | 494    |\n",
    "\n",
    "To compute the odds ratio, it doesn't matter which variable we choose as response/explanatory (rows or columns).\n",
    "$$\n",
    "\\theta = \\frac{802(494)}{53(34)} = 219\n",
    "$$\n",
    "- $var(\\log \\theta) = \\sum_{i,j} \\frac{1}{n_{ij}} = 0.05155$\n",
    "- $E[\\log \\theta] = \\log \\theta = 5.392$\n",
    "- $\\mathcal{I}(\\theta) = \\exp( 5.389 \\pm q_{0.95} \\sqrt{0.05155} ) = [140.9, 343.1]$ \n",
    "\n",
    "---\n",
    "\n",
    "2.17 \n",
    "\n",
    "| Race  | Democrat | Republican | Independent |\n",
    "| ----- | -------- | ---------- | ----------- |\n",
    "| White | 871      | 821        | 336         |\n",
    "| Black | 347      | 42         | 83         |\n",
    "\n",
    "1. Test the null hypothesis of independence between political party and race.\n",
    "2. Use standardized residuals to describe evidence\n",
    "3. Partition chi-squared into two components, the first of which compares the races on the Dem/Rep choice. \n",
    "\n",
    "Chi-squared statistic\n",
    "Under $H_0$, the row and column marginal probabilities are\n",
    "- $\\pi_{1,:} = (\\sum^3_{j=1} \\pi_{1,j}) / n = 0.8112$\n",
    "- $\\pi_{2,:} = 1 - \\pi_{1,:} = 0.1888$\n",
    "- $\\pi_{:,1} = 0.4872$\n",
    "- $\\pi_{:,2} = 0.3452$\n",
    "- $\\pi_{:,3} = 0.1676$\n",
    "The observed probabilities are \n",
    "```julia\n",
    "2×3 Matrix{Float64}:\n",
    " 0.3484  0.3284  0.1344\n",
    " 0.1388  0.0168  0.0332\n",
    "```\n",
    "\n",
    "Then, $X^2 = 184.3$. We know $X^2 \\sim \\chi^2_2$. Thus, $P(Z \\geq X^2) = 0$, where $Z \\sim \\chi^2_2$. \n",
    "We have $G^2 = 213.9$, so $P(Z \\geq X^2) = 0$ as well.\n",
    "\n",
    "Standardized residuals\n",
    "```julia\n",
    "2×3 Matrix{Float64}:\n",
    " -11.9668   12.9995  -0.532628\n",
    "  11.9668  -12.9995   0.532628\n",
    "```\n",
    "- Fewer Whites were Democrats and fewer Blacks were Republicans, with similar magnitude of lack of fit to $H_0$ \n",
    "- independent were similar \n",
    "\n",
    "The first partition is \n",
    "| Race  | Democrat | Republican |\n",
    "| ----- | -------- | ---------- |\n",
    "| White | 871      | 821        |\n",
    "| Black | 347      | 42         |\n",
    " \n",
    "$X^2$ for this partition is 185.4.\n",
    "\n",
    "The second partition is \n",
    "| Race  | Democrat or Republican | Independent |\n",
    "| ----- | ---------------------- | ----------- |\n",
    "| White | 1692                   | 336         |\n",
    "| Black | 389                    | 83          |\n",
    "\n",
    "$X^2$ for this partition is 0.28.\n",
    "\n",
    "Together, $185.4 + 0.28 = 185.737$ which differs slightly from the total  $X^2$ of 184.3\n",
    "The p-value for the first and second partitions are 0 and 0.59. Thus, Democrat/Republican are not independent, but Democrat or Republican and Independent are independent.\n",
    "\n",
    "However, because $X^2$ does not partition completely, we should isntead use $G^2$\n",
    "- $G^2_1 = 213.6$\n",
    "- $G^2_2 = 0.28$\n",
    "\n",
    "---\n",
    "\n",
    "2.21 \n",
    "| Income | Very | LIttle | Moderately | Very Satisfied |\n",
    "| ------ | ---- | ------ | ---------- | -------------- |\n",
    "| <5     | 2    | 4      | 13         | 3              |\n",
    "| 5-15   | 2    | 6      | 22         | 4              |\n",
    "| 15-25  | 0    | 1      | 15         | 8              |\n",
    "| >25    | 0    | 3      | 13         | 8              |\n",
    "\n",
    "$X^2 = 11.5$, giving p-value $1 - P(Z \\leq 11.5) = 0.24$\n",
    "\n",
    "Standardized residuals\n",
    "```julia\n",
    "4×4 Matrix{Float64}:\n",
    "  1.44062    0.730528  -0.160626  -1.07918\n",
    "  0.752542   0.871575   0.600508  -1.77257\n",
    " -1.11714   -1.52114    0.219809   1.50979\n",
    " -1.11714   -0.157359  -0.732696   1.50979\n",
    "```\n",
    "strongest assocaitions are\n",
    "- income 5-15 unlikely to be very satisfied \n",
    "- <5 income likely to be very unsatisfied\n",
    "- income 15-25 unlikely to be little unsatisfied\n",
    "- income 15-25 and >25 likely to be very satisfied \n",
    "\n",
    "Sample correlation\n",
    "- $u = [3, 10, 20, 35]$\n",
    "- $v = [1, 3, 4, 5]$\n",
    "- p-value is 0.008, which gives much stronger evidence of a trend due to higher power when exploiting ordinality in data \n",
    "\n",
    "```julia\n",
    "julia> data = [2 4 13 3; 2 6 22 4; 0 1 15 8; 0 3 13 8]\n",
    "4×4 Matrix{Int64}:\n",
    " 2  4  13  3\n",
    " 2  6  22  4\n",
    " 0  1  15  8\n",
    " 0  3  13  8\n",
    "\n",
    "julia> u = [3, 10, 20, 35]; v = [1, 3, 4, 5]\n",
    "4-element Vector{Int64}:\n",
    " 1\n",
    " 3\n",
    " 4\n",
    " 5\n",
    "\n",
    "julia> N = sum(data)\n",
    "104\n",
    "\n",
    "julia> p_rows = (data * ones(4)) ./ N; p_cols = (data' * ones(4)) ./ N;\n",
    "\n",
    "julia> u_avg = u' * p_rows; v_avg = v' * p_cols\n",
    "\n",
    "julia> u_var = sum(((u .- u_avg) .^ 2) .* p_rows); \n",
    "\n",
    "julia> v_var = sum(((v .- v_avg) .^ 2) .* p_cols);\n",
    "\n",
    "julia> numer = ((u .- u_avg) * (v .- v_avg)') .* (data ./ N)\n",
    "4×4 Matrix{Float64}:\n",
    "  0.776851   0.507845   -0.0490246  -0.40351\n",
    "  0.376888   0.36957    -0.0402502  -0.261016\n",
    " -0.0       -0.0317852   0.0141617   0.269387\n",
    " -0.0       -0.515566    0.06636     1.45652\n",
    "\n",
    "julia> numer = sum(numer)\n",
    "2.5364275147928996\n",
    "\n",
    "julia> denom = sqrt(u_var*v_var)\n",
    "9.698507695372635\n",
    "\n",
    "julia> M2 = (N-1)*(numer/denom)^2\n",
    "7.04485902193063\n",
    "\n",
    "julia> p = 1 - cdf(Chisq(1), M2) \n",
    "0.007949308126710797\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "2.23 \n",
    "| Treatment | Cancer Controlled | Cancer not controlled |\n",
    "| --------- | ----------------- | --------------------- |\n",
    "| Surgery   | 21                | 2                     |\n",
    "| Radiation | 15                | 3                     |\n",
    "\n",
    "Fisher's exact test uses the hypergeometric distribution.\n",
    "\n",
    "$$\n",
    "\\begin{align} \n",
    "P(n=21) &= \n",
    "\\frac{\n",
    "\t(n \\in \\text{surgery})\n",
    "\t(\\# \\text{controlled} - n \\in \\text{radiation})\n",
    "}{\\# \\text{controlled} \\in N} \\\\\n",
    "&= \\frac{\n",
    "\t\\begin{pmatrix} 23 \\\\ 21 \\end{pmatrix} \n",
    "\t\\begin{pmatrix} 18 \\\\ 15 \\end{pmatrix}\n",
    "}{\\begin{pmatrix} 41 \\\\ 36 \\end{pmatrix}} =\n",
    "0.2755\n",
    "\\end{align} \n",
    "$$\n",
    "The more extreme possibilities are $n=\\{22, 23\\}$. \n",
    "- $P(n=22) = 0.094$\n",
    "- $P(n=23) = 0.011$\n",
    "- Thus, the p-value of more extreme possibilities that are strictly greater than observed is $\\sum^{23}_{i=21} P(n=i) = 0.3808$\n",
    "\n",
    "The two-sided test also considers the more extreme possibilities $n = \\{18, 19\\}$. \n",
    "$$\\sum^{23}_{i=18, \\ i \\neq 20} P(n=i) = 0.6384$$\n",
    "\n",
    "---\n",
    "\n",
    "2.25 \n",
    "| Victim | Defendant | Death | No Death |\n",
    "| ------ | --------- | ----- | -------- |\n",
    "| White  | White     | 19    | 132      |\n",
    "|        | Black     | 11    | 52       |\n",
    "| Black  | White     | 0     | 9        |\n",
    "|        | Black     | 6     | 97       |\n",
    "\n",
    "Conditional odds ratio for defendant race x death penalty \n",
    "- conditioned on victim race, we just take the 2x2 for a given victime race\n",
    "- $\\theta \\mid \\text{white victim} = \\frac{19(52)}{11(132)} = 0.6804$\n",
    "- $\\theta \\mid \\text{black victim} = 0$\n",
    "\n",
    "Marginal odds ratio between defendant race and death penalty\n",
    "- marginalize victim race by summing rows\n",
    "$\\theta = \\frac{19(97+52)}{(132+9)(6+11)}  = 1.181$\n",
    "\n",
    "Yes, Simpson's paradox => marginal and condl associations are in different directions. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
